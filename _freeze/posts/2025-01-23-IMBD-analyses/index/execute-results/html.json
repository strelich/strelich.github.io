{
  "hash": "052702138ba508127cd7958ea22305fb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"IMDB Data Wrangling\"\ndescription: \"Wrangling IMBD data and modelling with tidymodels\"\nauthor: \"Jack Strelich\"\ndate: 2025-01-23\ncategories: [R, Data Cleaning, Data Visualization, Analysis]\ndraft: false\nformat: \n  html: \n    df-print: paged\n# image: \"index_files/figure-html/fig-plot-captions-1.png\"\n---\n\n\nToday, I'll explore some data on movies from [IMDB](https://developer.imdb.com/non-commercial-datasets/) and [Box Office Mojo](https://www.boxofficemojo.com/chart/top_lifetime_gross/). I'll begin with some quick data wrangling, then walk through modelling the data with the `tidymodels` package. I've been experimenting with this package a lot recently, and am particularly impressed by how it streamlines running multiple models and comparing the results. Note that this won't be a full-fledged tutorial for `tidymodels` (the `tidymodels` [docs](https://www.tidymodels.org/start/) cover that very well) nor a deep dive into the models themselves, but more of a worked example.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages\nlibrary(tidymodels) # Modelling\nlibrary(broom) # Extracting coefficients\nlibrary(yardstick) # Evaluating models\nlibrary(vip) # Variable importance\n\nlibrary(rvest) # For webscraping\n\nlibrary(tidyverse) # Data wrangling\nlibrary(ggrepel) # Extra data viz\n\n# Set theme for plots\ntheme_set(theme_minimal())\n```\n:::\n\n\n# Gather data\n\n## IMDB\n\nThe [IMDB Non-Commercial Datasets](https://developer.imdb.com/non-commercial-datasets/) page lists the data sets available, as well as a dictionary for each one. Six data sets contain information about titles (movie, TV show, video game, etc.) and one contains info about individuals. These data sets are quite large; the ratings data includes about 1.5 million titles, and the individuals data includes over 14 million names. To keep things tractable, we'll limit our exploration to movies with at least 1000 individual ratings (\"votes\").\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read ratings data\nratings_dat <- read_tsv(\"https://datasets.imdbws.com/title.ratings.tsv.gz\",\n                        show_col_types = FALSE) %>% \n  filter(numVotes >= 1000) # Only titles with at least 1000 votes\n\n# Read names data\nnames_dat <- read_tsv(\"https://datasets.imdbws.com/name.basics.tsv.gz\", \n                      show_col_types = FALSE,\n                      na = \"\\\\N\")\n\n# Read crew data\ncrew_dat <- read_tsv(\"https://datasets.imdbws.com/title.crew.tsv.gz\", \n                     show_col_types = FALSE,\n                     na = \"\\\\N\")\n```\n:::\n\n\nFor the main title data set (`title.basics.tsv.gz`), we'll do a little more data cleaning up front. Specifically, we'll:\n\n- Limit ourselves to movies (i.e., excluding TV shows, video games, and other types of media)\n- Exclude adult content (keeping thing SFW!)\n- Read release year and run time as integers\n- Split the `genres` column (currently a series of comma-separated tags) into multiple binary variables (1 if the tag applies, 0 otherwise)\n\nUsing [lazy reading](https://www.tidyverse.org/blog/2021/11/readr-2-1-0-lazy/) via the `lazy = TRUE` argument to `read_tsv()` helps to speed up this process, although in my experience the real bottleneck is downloading the data in the first place.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_dat <- read_tsv(\"https://datasets.imdbws.com/title.basics.tsv.gz\",\n                      na = \"\\\\N\",\n                      show_col_types = FALSE,\n                      lazy = TRUE) %>% # Don't load everything into memory!\n  filter(titleType == \"movie\", # Only movies\n         isAdult == 0) %>% # Not adult!\n  mutate(startYear = as.integer(startYear),\n         runtimeMinutes = as.integer(runtimeMinutes)) %>% \n  select(-c(isAdult,endYear)) %>% # Drop unneeded columns\n  separate_longer_delim(genres, delim = \",\") %>% # Split tags into multiple rows\n  mutate(temp=1) %>% # Create column of 1s\n  pivot_wider(names_from = genres, # Make wider; one column per genre\n              values_from = temp,\n              values_fill = 0,\n              names_prefix = \"Genre_\") # Set naming convention for new columns\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: There was 1 warning in `filter()`.\nℹ In argument: `titleType == \"movie\"`.\nCaused by warning:\n! One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n\n\n:::\n\n```{.r .cell-code}\n# Check work\ntitle_dat %>% head(10)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"tconst\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"titleType\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"primaryTitle\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"originalTitle\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"startYear\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"runtimeMinutes\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Romance\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Documentary\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_News\"],\"name\":[9],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Sport\"],\"name\":[10],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_NA\"],\"name\":[11],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Action\"],\"name\":[12],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Adventure\"],\"name\":[13],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Biography\"],\"name\":[14],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Drama\"],\"name\":[15],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Fantasy\"],\"name\":[16],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Comedy\"],\"name\":[17],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_War\"],\"name\":[18],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Crime\"],\"name\":[19],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Family\"],\"name\":[20],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_History\"],\"name\":[21],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Sci-Fi\"],\"name\":[22],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Thriller\"],\"name\":[23],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Western\"],\"name\":[24],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Mystery\"],\"name\":[25],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Horror\"],\"name\":[26],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Music\"],\"name\":[27],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Animation\"],\"name\":[28],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Musical\"],\"name\":[29],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Film-Noir\"],\"name\":[30],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Talk-Show\"],\"name\":[31],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Reality-TV\"],\"name\":[32],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Adult\"],\"name\":[33],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Genre_Game-Show\"],\"name\":[34],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"tt0000009\",\"2\":\"movie\",\"3\":\"Miss Jerry\",\"4\":\"Miss Jerry\",\"5\":\"1894\",\"6\":\"45\",\"7\":\"1\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000147\",\"2\":\"movie\",\"3\":\"The Corbett-Fitzsimmons Fight\",\"4\":\"The Corbett-Fitzsimmons Fight\",\"5\":\"1897\",\"6\":\"100\",\"7\":\"0\",\"8\":\"1\",\"9\":\"1\",\"10\":\"1\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000502\",\"2\":\"movie\",\"3\":\"Bohemios\",\"4\":\"Bohemios\",\"5\":\"1905\",\"6\":\"100\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"1\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000574\",\"2\":\"movie\",\"3\":\"The Story of the Kelly Gang\",\"4\":\"The Story of the Kelly Gang\",\"5\":\"1906\",\"6\":\"70\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"1\",\"13\":\"1\",\"14\":\"1\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000591\",\"2\":\"movie\",\"3\":\"The Prodigal Son\",\"4\":\"L'enfant prodigue\",\"5\":\"1907\",\"6\":\"90\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"1\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000615\",\"2\":\"movie\",\"3\":\"Robbery Under Arms\",\"4\":\"Robbery Under Arms\",\"5\":\"1907\",\"6\":\"NA\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"1\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000630\",\"2\":\"movie\",\"3\":\"Hamlet\",\"4\":\"Amleto\",\"5\":\"1908\",\"6\":\"NA\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"1\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000675\",\"2\":\"movie\",\"3\":\"Don Quijote\",\"4\":\"Don Quijote\",\"5\":\"1908\",\"6\":\"NA\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"1\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000679\",\"2\":\"movie\",\"3\":\"The Fairylogue and Radio-Plays\",\"4\":\"The Fairylogue and Radio-Plays\",\"5\":\"1908\",\"6\":\"120\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"0\",\"12\":\"0\",\"13\":\"1\",\"14\":\"0\",\"15\":\"0\",\"16\":\"1\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"},{\"1\":\"tt0000838\",\"2\":\"movie\",\"3\":\"A Cultura do Cacau\",\"4\":\"A Cultura do Cacau\",\"5\":\"1909\",\"6\":\"NA\",\"7\":\"0\",\"8\":\"0\",\"9\":\"0\",\"10\":\"0\",\"11\":\"1\",\"12\":\"0\",\"13\":\"0\",\"14\":\"0\",\"15\":\"0\",\"16\":\"0\",\"17\":\"0\",\"18\":\"0\",\"19\":\"0\",\"20\":\"0\",\"21\":\"0\",\"22\":\"0\",\"23\":\"0\",\"24\":\"0\",\"25\":\"0\",\"26\":\"0\",\"27\":\"0\",\"28\":\"0\",\"29\":\"0\",\"30\":\"0\",\"31\":\"0\",\"32\":\"0\",\"33\":\"0\",\"34\":\"0\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n## Box Office Mojo\n\nWe'll supplement the titles data with information on lifetime gross. Conveniently, [Box Office Mojo](https://www.boxofficemojo.com/chart/top_lifetime_gross/) lists the top 1000 domestic films by lifetime gross; less conveniently, the information is in a paged table. To save a bunch of copying and pasting, we'll do some basic webscraping to get this information into a single data frame.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create vector of URLs, one for each page of the table\nURLs <- paste0(\"https://www.boxofficemojo.com/chart/top_lifetime_gross/?offset=\", \n               0:4*200)\n\n# Loop over URLs\ntop_gross <- map(\n  URLs, \\(url) \n  read_html(url) %>% # For each URL...\n    html_elements(\"table\") %>% # Pick out the table\n    html_table() %>% # Read the table as a list\n    pluck(1) %>% # Get the first element (the actual data)\n    # Remove commas and make into integers\n    mutate(Rank=str_remove(Rank,\"\\\\,\") %>% as.integer(), \n           `Lifetime Gross`=str_remove_all(`Lifetime Gross`,\"\\\\,|\\\\$\") %>% \n             as.integer())) %>% \n  list_rbind() # Combine into single data frame\n\n# Check work\ntop_gross %>% head(10)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Rank\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Title\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"Lifetime Gross\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Year\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"1\",\"2\":\"Star Wars: Episode VII - The Force Awakens\",\"3\":\"936662225\",\"4\":\"2015\"},{\"1\":\"2\",\"2\":\"Avengers: Endgame\",\"3\":\"858373000\",\"4\":\"2019\"},{\"1\":\"3\",\"2\":\"Spider-Man: No Way Home\",\"3\":\"814866759\",\"4\":\"2021\"},{\"1\":\"4\",\"2\":\"Avatar\",\"3\":\"785221649\",\"4\":\"2009\"},{\"1\":\"5\",\"2\":\"Top Gun: Maverick\",\"3\":\"718732821\",\"4\":\"2022\"},{\"1\":\"6\",\"2\":\"Black Panther\",\"3\":\"700426566\",\"4\":\"2018\"},{\"1\":\"7\",\"2\":\"Avatar: The Way of Water\",\"3\":\"684075767\",\"4\":\"2022\"},{\"1\":\"8\",\"2\":\"Avengers: Infinity War\",\"3\":\"678815482\",\"4\":\"2018\"},{\"1\":\"9\",\"2\":\"Titanic\",\"3\":\"674292608\",\"4\":\"1997\"},{\"1\":\"10\",\"2\":\"Jurassic World\",\"3\":\"653406625\",\"4\":\"2015\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n## Join data sets\n\nLet's join our title (`title_dat`), ratings (`ratings_dat`), and domestic gross (`top_gross`) data sets into a single data frame. `title_dat` and `ratings_dat` will automatically join using the unique title identifiers (`tconst`) present in both data sets. For the domestic gross data, we'll join by title and release year; because these variables have different names in the title data and domestic gross data (`originalTitle` versus `Title` and `startYear` versus `Year`), we'll need to specify which columns in each data set are equivalent, using `join_by()`.\n\nNote the use of `inner_join()` to join the title and rating data; this ensures that we retain only titles that have ratings associated with them (and at least 1000 votes, thanks to our earlier filtering of the ratings data). In contrast, we join the domestic gross data using `left_join()`, meaning that we retain titles from the title data even if they don't appear in the domestic gross data.\n\nLastly, we'll join `crew_dat` to get unique identifiers for each movie's director, then join `names_dat` to get the actual names associated with each identifier[^individual].\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_dat <- title_dat %>% # Start with title data set  \n  inner_join(ratings_dat) %>% # Join ratings data set (use tconst as key)\n  left_join(top_gross,  # Join gross data set\n            by = join_by(originalTitle == Title, # Col names differ -- specify!\n                         startYear == Year)) %>% \n  left_join(crew_dat) %>% # Join crew data set\n  left_join(select(names_dat, # Names!\n                   directors=nconst, # Rename variables to match\n                   Director=primaryName)) %>%  \n  select(tconst, primaryTitle:runtimeMinutes, averageRating, numVotes, # Reorganize columns\n         `Lifetime Gross`, Director, starts_with(\"Genre\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(tconst)`\nJoining with `by = join_by(tconst)`\nJoining with `by = join_by(directors)`\n```\n\n\n:::\n:::\n\n\n[^individual]: This approach only works for films with a single director; we'll stick with it here because the alternative would make our data structure more complicated.\n\n# Explore\n\n## Descriptives\n\nLet's check our work thus far via `glimpse()`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_dat %>% glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 44,716\nColumns: 37\n$ tconst             <chr> \"tt0002130\", \"tt0002423\", \"tt0002844\", \"tt0003014\",…\n$ primaryTitle       <chr> \"Dante's Inferno\", \"Passion\", \"Fantômas: In the Sha…\n$ originalTitle      <chr> \"L'inferno\", \"Madame DuBarry\", \"Fantômas I: À l'omb…\n$ startYear          <int> 1911, 1919, 1913, 1913, 1913, 1913, 1913, 1914, 191…\n$ runtimeMinutes     <int> 71, 113, 54, 96, 61, 90, 85, 78, 148, 52, 59, 70, 6…\n$ averageRating      <dbl> 7.0, 6.6, 6.9, 7.0, 6.9, 6.9, 6.4, 6.4, 7.1, 6.0, 6…\n$ numVotes           <dbl> 3704, 1049, 2598, 1493, 1765, 1405, 2522, 1493, 409…\n$ `Lifetime Gross`   <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ Director           <chr> NA, \"Ernst Lubitsch\", \"Louis Feuillade\", \"Victor Sj…\n$ Genre_Romance      <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ Genre_Documentary  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_News         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Sport        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_NA           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Action       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, …\n$ Genre_Adventure    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ Genre_Biography    <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Drama        <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, …\n$ Genre_Fantasy      <dbl> 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Comedy       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …\n$ Genre_War          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Crime        <dbl> 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, …\n$ Genre_Family       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_History      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ `Genre_Sci-Fi`     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Thriller     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Western      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Mystery      <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Horror       <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, …\n$ Genre_Music        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Animation    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Musical      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ `Genre_Film-Noir`  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ `Genre_Talk-Show`  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ `Genre_Reality-TV` <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ Genre_Adult        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ `Genre_Game-Show`  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n```\n\n\n:::\n:::\n\n\nWe see the following variables:\n\n- `tconst`: unique identifier for each movie\n- `primaryTitle`: main title by which the movie is known\n<!-- - `originalTitle`: original title of movie (e.g., non-English title) -->\n- `startYear`: year movie was released\n- `runtimeMinutes`: movie's runtime, in minutes (natch)\n- `averageRating`: average of all ratings (1-10 scale)\n- `numVotes`: total number of ratings received \n- `Lifetime Gross`: lifetime domestic gross of movie; only available for the top 1000 highest-grossing movies in our data set\n- `Director`: name of movie's director; `NA` if more than one director\n- `Genre_X`: genre tags (`1` if the tag applies, `0` otherwise)\n\nWe can get a quick-and-dirty overview of our continuous variables via `summary()`, and a breakdown of the distributions of (and correlations[^corrs] between) these variables via `GGally::ggpairs()`:\n\n[^corrs]: We'll use Spearman's rho to estimate correlation since some of our variables aren't normally distributed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_dat %>% \n  select(\"startYear\",\"runtimeMinutes\",\n         \"averageRating\",\"numVotes\",\"Lifetime Gross\") %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   startYear    runtimeMinutes  averageRating     numVotes      \n Min.   :1911   Min.   : 39.0   Min.   :1.00   Min.   :   1000  \n 1st Qu.:1989   1st Qu.: 91.0   1st Qu.:5.60   1st Qu.:   1673  \n Median :2008   Median :100.0   Median :6.40   Median :   3334  \n Mean   :2000   Mean   :105.2   Mean   :6.24   Mean   :  25486  \n 3rd Qu.:2017   3rd Qu.:115.0   3rd Qu.:7.10   3rd Qu.:  10645  \n Max.   :2025   Max.   :776.0   Max.   :9.80   Max.   :2994771  \n                NA's   :84                                      \n Lifetime Gross     \n Min.   : 85297000  \n 1st Qu.:105874210  \n Median :137275620  \n Mean   :174204573  \n 3rd Qu.:196461860  \n Max.   :936662225  \n NA's   :43757      \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_dat %>% \n  select(\"startYear\",\"runtimeMinutes\",\n         \"averageRating\",\"numVotes\",\"Lifetime Gross\") %>% \n  GGally::ggpairs(\n    lower = list(continuous = GGally::wrap(\"points\", # Handle overplotting\n                                           alpha = 0.1, \n                                           size = 1)),\n    upper = list(continuous = GGally::wrap(GGally::ggally_cor, \n                                           method = \"spearman\",\n                                           use = \"pairwise\",\n                                           title = \"Rho\"))\n  ) + labs(title = \"Distributions and correlations of continuous variables\",\n           caption = \"Data from datasets.imdbws.com\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nMajor takeaways:\n\n- `startYear`: most movies in the data set are relatively recent (post-2008)\n- `runtimeMinutes`: extreme positive skew. Digging around in the raw data, I found a handful of cases where a miniseries was treated as a single movie, or where the date was copied into the runtime column, but also at least one 25-hour-long movie!\n- `numVotes`: extreme positive skew!\n- Correlations between these variables are statistically significant, but small enough that we shouldn't have glaring issues with multicollinearity (although the correlation between `numVotes` and `Lifetime Gross` is potentially troublesome).\n\n## Visualization\n\nLet's start by examining which movies got the most votes overall. Because we joined the crew data, we can also include directors' names in the plot!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Most votes overall\ntitle_dat %>% \n  slice_max(order_by = numVotes, n = 20) %>% # Top 20 films\n  mutate(Label = paste0(primaryTitle,\"\\n(\",Director,\")\")) %>% # Add directors\n  ggplot(aes(x = fct_inorder(Label) %>% fct_rev, y = numVotes)) + \n  geom_col(fill=\"dodgerblue\") + \n  geom_text(aes(label = format(numVotes,big.mark = \",\")), \n            color = \"white\", nudge_y = -3*10^5) +\n  coord_flip() + \n  scale_y_continuous(labels = scales::label_number(big.mark = \",\")) +\n  labs(x = \"Movie\", y=\"Total votes\", \n       title = \"Top 20 movies by number of votes\",\n       caption = \"Data from datasets.imdbws.com\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nUnsurprisingly, we see a mix of (relatively) recent blockbusters such as _Interstellar_ and _The Wolf of Wall Street_ as well as older classics like _The Godfather_ and _Silence of the Lambs_. \n\nNext, let's look at the relationship between ratings and lifetime gross. We'll use `ggrepel::geom_text_repel()` to label the highest-grossing films (those making more than $500 million).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_dat %>% \n  drop_na(`Lifetime Gross`) %>% \n  ggplot(aes(x = averageRating, y = `Lifetime Gross`)) + \n  geom_point()+\n  geom_text_repel(data = filter(title_dat, `Lifetime Gross` > 500000000), \n                  aes(label = primaryTitle),\n                  color = \"firebrick\") +\n  scale_y_continuous(labels = scales::label_dollar()) +\n  labs(x = \"Average rating\",\n       y = \"Lifetime domestic gross\",\n       title = \"Lifetime domestic gross by average rating\",\n       caption = \"Includes only top 1000 movies by lifetime domestic gross.\n       Data from datasets.imdbws.com and boxofficemojo.com/chart/top_lifetime_gross\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: ggrepel: 1 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nFinally, let's look at the frequency of each genre tag in the data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_dat %>% \n  select(starts_with(\"Genre_\")) %>% \n  pivot_longer(everything(), names_prefix = \"Genre_\") %>% \n  filter(value==1) %>% \n  count(name, sort = TRUE) %>% # Get frequency of each tag\n  ggplot(aes(x=fct_rev(fct_inorder(name)),y=n)) + # Order by frequency\n  geom_col(fill=\"darkblue\") + \n  geom_text(aes(y = ifelse(n>3000, n-1500, n+1000), color = n > 3000,\n    label = format(n,big.mark = \",\"))) +\n  scale_y_continuous(labels = scales::label_number(big.mark = \",\")) +\n  coord_flip() +\n  scale_color_manual(values = c(\"black\",\"white\")) +\n  theme(legend.position = \"none\") +\n  labs(x = \"Genre\", y = \"Frequency\",\n       title = \"Frequency of genre tags\",\n       caption = \"Data from datasets.imdbws.com\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nDrama and comedy are the most frequent tags by a pretty substantial margin!\n\n\n# Model\n\nLet's shift gears and try building some models with this data via `tidymodels`. As I mentioned earlier, this won't be a full tutorial for `tidymodels` or a deep dive into the models themselves, but rather a worked example of how `tidymodels` allows us to easily run and compare multiple models. Take our findings with a grain of salt; these models will be very quick, back-of-the-envelope affairs, and we'll skip over a lot of the steps we'd take if we were actually trying to make significant real-world decisions based on the outputs.\n\n## Lifetime gross\n\nTo start, let's make a model to investigate which variables best predict lifetime gross. Because we only have lifetime gross data for the 1000 highest grossing movies in our data set, this will substantially decrease our sample size:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define our data set\ngross_dat <- title_dat %>% \n  filter(runtimeMinutes < 300, # Drop movies over 5hrs long...\n         !is.na(startYear), # Those missing release year...\n         !is.na(`Lifetime Gross`)) %>% # And those missing gross data\n  select(tconst,\n         primaryTitle,\n         gross = `Lifetime Gross`,\n         averageRating,\n         numVotes,\n         startYear, \n         runtimeMinutes, \n         starts_with(\"Genre_\")) %>% \n  select(-c('Genre_News', 'Genre_NA', # Drop columns for genres that don't occur\n            'Genre_Talk-Show', 'Genre_Reality-TV', 'Genre_Game-Show'))\n\nglimpse(gross_dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 959\nColumns: 30\n$ tconst            <chr> \"tt0029583\", \"tt0031381\", \"tt0034492\", \"tt0042332\", …\n$ primaryTitle      <chr> \"Snow White and the Seven Dwarfs\", \"Gone with the Wi…\n$ gross             <int> 184925486, 200882193, 102247150, 93141149, 87404651,…\n$ averageRating     <dbl> 7.6, 8.2, 7.3, 7.3, 7.3, 7.3, 7.3, 7.8, 7.9, 8.1, 8.…\n$ numVotes          <dbl> 221758, 342617, 158217, 178774, 157776, 153329, 1875…\n$ startYear         <int> 1937, 1939, 1942, 1950, 1953, 1955, 1961, 1964, 1965…\n$ runtimeMinutes    <int> 83, 238, 69, 74, 77, 76, 79, 139, 197, 172, 106, 78,…\n$ Genre_Romance     <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0…\n$ Genre_Documentary <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Sport       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Action      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0…\n$ Genre_Adventure   <dbl> 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0…\n$ Genre_Biography   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Genre_Drama       <dbl> 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0…\n$ Genre_Fantasy     <dbl> 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Comedy      <dbl> 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0…\n$ Genre_War         <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Crime       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0…\n$ Genre_Family      <dbl> 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_History     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ `Genre_Sci-Fi`    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Thriller    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0…\n$ Genre_Western     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Mystery     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Horror      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ Genre_Music       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Animation   <dbl> 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0…\n$ Genre_Musical     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ `Genre_Film-Noir` <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Adult       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n```\n\n\n:::\n:::\n\n\nNext, we'll define a recipe to preprocess our data. This recipe will:\n\n- Predict lifetime gross (`gross`) from all other predictors\n- Treat `tconst` and `primaryTitle` as identifiers\n- Log-transform `gross` and `numVotes` to handle deviation from normality\n- Normalize all continuous predictors (i.e., convert to z-scores)\n- Remove predictors with no variance\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the recipe\nlm_gross_rec <- recipe(gross ~ ., gross_dat) %>% # Predict gross from all others\n  update_role(tconst,primaryTitle,new_role = \"ID\") %>% # Treat as identifiers\n  step_log(gross, numVotes) %>% # Log transform gross and number of votes\n  step_normalize(startYear,runtimeMinutes,numVotes,gross) %>% # Normalize\n  step_zv(all_predictors()) # Remove predictors with no variance\n```\n:::\n\n\nFinally, we'll fit the model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit model\nlm_gross_fit <- workflow() %>% \n  add_model(linear_reg()) %>% # Use linear regression\n  add_recipe(lm_gross_rec) %>% # Pre-process data via our recipie\n  fit(data = gross_dat) # Fit using our data set\n\nlm_gross_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_log()\n• step_normalize()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n      (Intercept)      averageRating           numVotes          startYear  \n        -0.472949           0.039284           0.432938           0.112942  \n   runtimeMinutes      Genre_Romance  Genre_Documentary        Genre_Sport  \n         0.175688           0.009673           0.988917           0.050235  \n     Genre_Action    Genre_Adventure    Genre_Biography        Genre_Drama  \n         0.036221           0.341288          -0.202291          -0.134246  \n    Genre_Fantasy       Genre_Comedy          Genre_War        Genre_Crime  \n         0.231324           0.107008          -0.584406          -0.183351  \n     Genre_Family      Genre_History     `Genre_Sci-Fi`     Genre_Thriller  \n         0.067307          -0.197419           0.051611          -0.175678  \n    Genre_Western      Genre_Mystery       Genre_Horror        Genre_Music  \n        -0.132603          -0.362759           0.186564           0.113136  \n  Genre_Animation      Genre_Musical  \n         0.365934           0.154279  \n```\n\n\n:::\n:::\n\n\nTo make sense of the model results, let's visualize our coefficients via a dot-and-whisker plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbroom.mixed::tidy(lm_gross_fit, conf.int = TRUE) %>% # Get coefficients and CIs\n  drop_na(estimate) %>% \n  arrange(desc(estimate)) %>% \n  dotwhisker::dwplot(dot_args = list(size = 2, color = \"black\"),\n                     whisker_args = list(color = \"black\"),\n                     vline = geom_vline(xintercept = 0, \n                                        colour = \"grey50\", \n                                        linetype = 2)) + \n  labs(title = \"Predicting lifetime gross\", subtitle = \"Linear model\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nLooking at the first few variables, a film being a documentary, animation, adventure, and/or fantasy seems to predict higher lifetime gross. Similarly, more votes overall, longer runtimes, and more recent release dates also seem to predict higher lifetime gross. The fact that being a documentary predicts higher lifetime gross seems a little odd -- I don't usually think of documentaries as huge moneymakers. To investigate, let's see what documentaries are included in our data set for this model:\n\n\n::: {.cell tbl-cap='Predicting lifetime gross - Documentaries'}\n\n```{.r .cell-code}\ngross_dat %>% \n  filter(Genre_Documentary == 1) %>% \n  select(primaryTitle:runtimeMinutes)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"primaryTitle\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"gross\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"averageRating\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"numVotes\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"startYear\"],\"name\":[5],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"runtimeMinutes\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Space Station 3D\",\"2\":\"93383953\",\"3\":\"7.4\",\"4\":\"1768\",\"5\":\"2002\",\"6\":\"47\"},{\"1\":\"Fahrenheit 9/11\",\"2\":\"119194771\",\"3\":\"7.5\",\"4\":\"133399\",\"5\":\"2004\",\"6\":\"122\"},{\"1\":\"Jackass 3D\",\"2\":\"117229692\",\"3\":\"7.0\",\"4\":\"69502\",\"5\":\"2010\",\"6\":\"94\"},{\"1\":\"Taylor Swift: The Eras Tour\",\"2\":\"180756269\",\"3\":\"8.0\",\"4\":\"23719\",\"5\":\"2023\",\"6\":\"169\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nCrucially, we only have four documentaries in our entire data set -- this explains the very wide confidence interval for this coefficient in our dot-and-whisker plot. More to the point, the documentaries we have are an  IMAX 3D feature about the International Space Station, a controversial Michael Moore documentary, Jackass 3D (self-explanatory), and a chronicle of Taylor Swift's Eras Tour. Overall, I'd say we're looking at a specific type of selection bias; the documentaries that make it into the top 1000 grossing films aren't necessarily representative of documentaries in general.\n\n\nLastly, let's look at the ten highest and lowest residuals in our results; these are the movies whose lifetime gross was most underestimated and overestimated (respectively) by the model:\n\n\n::: {.cell tbl-cap='Predicting lifetime gross - Highest residuals'}\n\n```{.r .cell-code}\naugment(lm_gross_fit, gross_dat) %>% \n  slice_max(.resid, n=10) %>% \n  select(.resid, .pred, primaryTitle:runtimeMinutes)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".resid\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".pred\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"primaryTitle\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"gross\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"averageRating\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"numVotes\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"startYear\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"runtimeMinutes\"],\"name\":[8],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"2.811748\",\"2\":\"0.50559753\",\"3\":\"Top Gun: Maverick\",\"4\":\"718732821\",\"5\":\"8.2\",\"6\":\"753270\",\"7\":\"2022\",\"8\":\"130\"},{\"1\":\"2.734704\",\"2\":\"1.15118532\",\"3\":\"Star Wars: Episode VII - The Force Awakens\",\"4\":\"936662225\",\"5\":\"7.8\",\"6\":\"991722\",\"7\":\"2015\",\"8\":\"138\"},{\"1\":\"2.614653\",\"2\":\"0.49672181\",\"3\":\"Inside Out 2\",\"4\":\"652980194\",\"5\":\"7.6\",\"6\":\"199450\",\"7\":\"2024\",\"8\":\"96\"},{\"1\":\"2.320801\",\"2\":\"-0.03222423\",\"3\":\"Moana 2\",\"4\":\"445091599\",\"5\":\"7.0\",\"6\":\"66256\",\"7\":\"2024\",\"8\":\"100\"},{\"1\":\"2.280776\",\"2\":\"0.83200049\",\"3\":\"Jurassic World\",\"4\":\"653406625\",\"5\":\"6.9\",\"6\":\"694693\",\"7\":\"2015\",\"8\":\"124\"},{\"1\":\"2.279169\",\"2\":\"0.55893692\",\"3\":\"The Super Mario Bros. Movie\",\"4\":\"574934330\",\"5\":\"7.0\",\"6\":\"258483\",\"7\":\"2023\",\"8\":\"92\"},{\"1\":\"2.236211\",\"2\":\"0.82111554\",\"3\":\"Deadpool & Wolverine\",\"4\":\"636745858\",\"5\":\"7.6\",\"6\":\"454957\",\"7\":\"2024\",\"8\":\"128\"},{\"1\":\"2.203411\",\"2\":\"1.05854689\",\"3\":\"Black Panther\",\"4\":\"700426566\",\"5\":\"7.3\",\"6\":\"861789\",\"7\":\"2018\",\"8\":\"134\"},{\"1\":\"2.203181\",\"2\":\"0.51476371\",\"3\":\"The Lion King\",\"4\":\"543638043\",\"5\":\"6.8\",\"6\":\"278229\",\"7\":\"2019\",\"8\":\"118\"},{\"1\":\"2.192322\",\"2\":\"1.50618592\",\"3\":\"Avengers: Endgame\",\"4\":\"858373000\",\"5\":\"8.4\",\"6\":\"1327991\",\"7\":\"2019\",\"8\":\"181\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell tbl-cap='Predicting lifetime gross - Lowest residuals'}\n\n```{.r .cell-code}\naugment(lm_gross_fit, gross_dat) %>% \n  slice_min(.resid, n=10) %>% \n  select(.resid, .pred, primaryTitle:runtimeMinutes)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".resid\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".pred\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"primaryTitle\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"gross\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"averageRating\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"numVotes\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"startYear\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"runtimeMinutes\"],\"name\":[8],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-1.882086\",\"2\":\"0.7176603\",\"3\":\"Oblivion\",\"4\":\"89107235\",\"5\":\"7.0\",\"6\":\"565448\",\"7\":\"2013\",\"8\":\"124\"},{\"1\":\"-1.865210\",\"2\":\"1.1313674\",\"3\":\"Dune: Part One\",\"4\":\"108897830\",\"5\":\"8.0\",\"6\":\"932875\",\"7\":\"2021\",\"8\":\"155\"},{\"1\":\"-1.733344\",\"2\":\"0.8209311\",\"3\":\"Edge of Tomorrow\",\"4\":\"100206256\",\"5\":\"7.9\",\"6\":\"762503\",\"7\":\"2014\",\"8\":\"113\"},{\"1\":\"-1.715188\",\"2\":\"0.4705222\",\"3\":\"Alita: Battle Angel\",\"4\":\"85838210\",\"5\":\"7.3\",\"6\":\"307308\",\"7\":\"2019\",\"8\":\"122\"},{\"1\":\"-1.673445\",\"2\":\"0.4889374\",\"3\":\"Back to the Future Part III\",\"4\":\"88277583\",\"5\":\"7.5\",\"6\":\"494717\",\"7\":\"1990\",\"8\":\"118\"},{\"1\":\"-1.673343\",\"2\":\"0.6888763\",\"3\":\"Schindler's List\",\"4\":\"96898818\",\"5\":\"9.0\",\"6\":\"1500915\",\"7\":\"1993\",\"8\":\"195\"},{\"1\":\"-1.648807\",\"2\":\"0.7370070\",\"3\":\"Kingsman: The Golden Circle\",\"4\":\"100234838\",\"5\":\"6.7\",\"6\":\"379505\",\"7\":\"2017\",\"8\":\"141\"},{\"1\":\"-1.626320\",\"2\":\"0.7478442\",\"3\":\"Pacific Rim\",\"4\":\"101802906\",\"5\":\"6.9\",\"6\":\"541497\",\"7\":\"2013\",\"8\":\"131\"},{\"1\":\"-1.620935\",\"2\":\"0.5546894\",\"3\":\"Dungeons & Dragons: Honor Among Thieves\",\"4\":\"93277026\",\"5\":\"7.2\",\"6\":\"251375\",\"7\":\"2023\",\"8\":\"134\"},{\"1\":\"-1.619005\",\"2\":\"0.4940252\",\"3\":\"Prince of Persia: The Sands of Time\",\"4\":\"90759676\",\"5\":\"6.5\",\"6\":\"309476\",\"7\":\"2010\",\"8\":\"116\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n## Average ratings\n\nNext up, let's see if we can predict a movie's average rating from its number of votes, release year, run time, and genre tags. To start, we'll create a new data frame by filtering out movies over 5 hours long and those missing a release year, and selecting only the variables we're interested in.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create data set\nrating_model_dat <- title_dat %>% \n  filter(runtimeMinutes < 300,\n         !is.na(startYear)) %>% \n  select(tconst,\n         primaryTitle,\n         averageRating,\n         numVotes,\n         startYear, \n         runtimeMinutes, \n         starts_with(\"Genre_\")) %>% \n  select(-c('Genre_News', 'Genre_NA', \n            'Genre_Talk-Show', 'Genre_Reality-TV', 'Genre_Game-Show'))\n\nglimpse(rating_model_dat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 44,608\nColumns: 29\n$ tconst            <chr> \"tt0002130\", \"tt0002423\", \"tt0002844\", \"tt0003014\", …\n$ primaryTitle      <chr> \"Dante's Inferno\", \"Passion\", \"Fantômas: In the Shad…\n$ averageRating     <dbl> 7.0, 6.6, 6.9, 7.0, 6.9, 6.9, 6.4, 6.4, 7.1, 6.0, 6.…\n$ numVotes          <dbl> 3704, 1049, 2598, 1493, 1765, 1405, 2522, 1493, 4095…\n$ startYear         <int> 1911, 1919, 1913, 1913, 1913, 1913, 1913, 1914, 1914…\n$ runtimeMinutes    <int> 71, 113, 54, 96, 61, 90, 85, 78, 148, 52, 59, 70, 60…\n$ Genre_Romance     <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ Genre_Documentary <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Sport       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Action      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0…\n$ Genre_Adventure   <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0…\n$ Genre_Biography   <dbl> 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Drama       <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1…\n$ Genre_Fantasy     <dbl> 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Comedy      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n$ Genre_War         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1…\n$ Genre_Crime       <dbl> 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ Genre_Family      <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_History     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ `Genre_Sci-Fi`    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Thriller    <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Western     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Mystery     <dbl> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Horror      <dbl> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0…\n$ Genre_Music       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Animation   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Musical     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ `Genre_Film-Noir` <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Genre_Adult       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n```\n\n\n:::\n:::\n\n\nNext, we'll split this data set into a _training_ and a _test_ set. The training set will used to train our models (hence the name); the test set will be used to evaluate how well they generalize to new data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1337) # Set seed for reproducibility\nrating_data_split <- initial_split(rating_model_dat, prop = 3/4)\nrating_data_train <- training(rating_data_split)\nrating_data_test <- testing(rating_data_split)\n```\n:::\n\n\nNow we'll specify a data pre-processing recipe that will:\n\n- Predict average rating (`averageRating`) from all other predictors\n- Treat `tconst` and `primaryTitle` as identifiers\n- Log-transform `numVotes` to handle deviation from normality\n- Normalize all continuous predictors (i.e., convert to z-scores)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the recipe\nrating_rec <- recipe(averageRating ~ ., rating_model_dat) %>% # Set formula\n  update_role(tconst, primaryTitle, new_role = \"ID\") %>% # Treat as identifiers\n  step_log(numVotes) %>% # Log transform to address deviation from normality\n  step_normalize(startYear, runtimeMinutes, numVotes) %>% # Normalize continuous\n  step_zv(all_predictors()) # Remove predictors with no variance\n```\n:::\n\n\nWe can reuse our work here with each model we run -- this is one of the big advantages of `tidymodels`!\n\n### Linear model\n\nFirst, let's fit a linear model to our training data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Fit model\nlm_rating_fit <- workflow() %>% # Set up workflow\n  add_model(linear_reg()) %>% # Use linear regression\n  add_recipe(rating_rec) %>%  # Use our pre-processing recipe\n  fit(data = rating_data_train) # Use training data set\n\n# Check results\nlm_rating_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_log()\n• step_normalize()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n      (Intercept)           numVotes          startYear     runtimeMinutes  \n        6.3188238          0.3084472         -0.3053317          0.2743756  \n    Genre_Romance  Genre_Documentary        Genre_Sport       Genre_Action  \n       -0.1205021          1.2775734         -0.1144554         -0.4181589  \n  Genre_Adventure    Genre_Biography        Genre_Drama      Genre_Fantasy  \n       -0.2825614          0.0420595          0.3336779         -0.2016875  \n     Genre_Comedy          Genre_War        Genre_Crime       Genre_Family  \n       -0.1212918         -0.0385408         -0.0321719         -0.1483447  \n    Genre_History     `Genre_Sci-Fi`     Genre_Thriller      Genre_Western  \n        0.0004387         -0.4777811         -0.1628879         -0.2258474  \n    Genre_Mystery       Genre_Horror        Genre_Music    Genre_Animation  \n       -0.0542027         -0.7826594         -0.0658001          0.8431900  \n    Genre_Musical  `Genre_Film-Noir`  \n       -0.1518250         -0.0612570  \n```\n\n\n:::\n:::\n\n\nAs we did for the lifetime gross model, let's visualize via a dot-and-whisker plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbroom.mixed::tidy(lm_rating_fit, conf.int = TRUE) %>% \n  drop_na(estimate) %>% \n  arrange(desc(estimate)) %>% \n  dotwhisker::dwplot(dot_args = list(size = 2, color = \"black\"),\n                     whisker_args = list(color = \"black\"),\n                     vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2)) + \n  labs(title = \"Predicting average ratings\", subtitle = \"Linear model\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\nOut of curiosity, let's see the 20 movies with the lowest (most) negative residuals -- in other words, the movies for which our model most overestimated ratings:\n\n\n::: {.cell tbl-cap='Predicting average ratings - Lowest residuals'}\n\n```{.r .cell-code}\naugment(lm_rating_fit, rating_model_dat) %>% \n  slice_min(.resid, n=20) %>% \n  select(.pred, .resid, primaryTitle:runtimeMinutes)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".pred\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".resid\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"primaryTitle\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"averageRating\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"numVotes\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"startYear\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"runtimeMinutes\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"7.952335\",\"2\":\"-6.252335\",\"3\":\"Justin Bieber: Never Say Never\",\"4\":\"1.7\",\"5\":\"76511\",\"6\":\"2011\",\"7\":\"105\"},{\"1\":\"7.066869\",\"2\":\"-6.066869\",\"3\":\"Reis\",\"4\":\"1.0\",\"5\":\"74214\",\"6\":\"2017\",\"7\":\"108\"},{\"1\":\"7.456796\",\"2\":\"-5.856796\",\"3\":\"Justin Bieber's Believe\",\"4\":\"1.6\",\"5\":\"17955\",\"6\":\"2013\",\"7\":\"92\"},{\"1\":\"7.348169\",\"2\":\"-5.748169\",\"3\":\"Jonas Brothers: The 3D Concert Experience\",\"4\":\"1.6\",\"5\":\"17567\",\"6\":\"2009\",\"7\":\"76\"},{\"1\":\"6.934861\",\"2\":\"-5.734861\",\"3\":\"Sadak 2\",\"4\":\"1.2\",\"5\":\"96910\",\"6\":\"2020\",\"7\":\"133\"},{\"1\":\"6.895741\",\"2\":\"-5.695741\",\"3\":\"Smolensk\",\"4\":\"1.2\",\"5\":\"40253\",\"6\":\"2016\",\"7\":\"120\"},{\"1\":\"7.026134\",\"2\":\"-5.626134\",\"3\":\"The Legend of the Titanic\",\"4\":\"1.4\",\"5\":\"3678\",\"6\":\"1999\",\"7\":\"84\"},{\"1\":\"7.448394\",\"2\":\"-5.548394\",\"3\":\"The Undefeated\",\"4\":\"1.9\",\"5\":\"1967\",\"6\":\"2011\",\"7\":\"118\"},{\"1\":\"6.465751\",\"2\":\"-5.465751\",\"3\":\"321 Action\",\"4\":\"1.0\",\"5\":\"10229\",\"6\":\"2020\",\"7\":\"100\"},{\"1\":\"6.336742\",\"2\":\"-5.336742\",\"3\":\"Cumali Ceber\",\"4\":\"1.0\",\"5\":\"39516\",\"6\":\"2017\",\"7\":\"100\"},{\"1\":\"7.012994\",\"2\":\"-5.312994\",\"3\":\"Humshakals\",\"4\":\"1.7\",\"5\":\"8972\",\"6\":\"2014\",\"7\":\"159\"},{\"1\":\"7.108319\",\"2\":\"-5.308319\",\"3\":\"Amazing China\",\"4\":\"1.8\",\"5\":\"3910\",\"6\":\"2018\",\"7\":\"90\"},{\"1\":\"6.757634\",\"2\":\"-5.257634\",\"3\":\"Titanic: The Legend Goes On...\",\"4\":\"1.5\",\"5\":\"9716\",\"6\":\"2000\",\"7\":\"90\"},{\"1\":\"6.493090\",\"2\":\"-5.193090\",\"3\":\"A Fox's Tale\",\"4\":\"1.3\",\"5\":\"9092\",\"6\":\"2008\",\"7\":\"85\"},{\"1\":\"6.718127\",\"2\":\"-5.118127\",\"3\":\"The Starfighters\",\"4\":\"1.6\",\"5\":\"3551\",\"6\":\"1964\",\"7\":\"78\"},{\"1\":\"6.605966\",\"2\":\"-5.105966\",\"3\":\"The Cost of Deception\",\"4\":\"1.5\",\"5\":\"40691\",\"6\":\"2021\",\"7\":\"125\"},{\"1\":\"6.194956\",\"2\":\"-5.094956\",\"3\":\"Nyay: The Justice\",\"4\":\"1.1\",\"5\":\"1678\",\"6\":\"2021\",\"7\":\"110\"},{\"1\":\"6.306746\",\"2\":\"-5.006746\",\"3\":\"Foodfight!\",\"4\":\"1.3\",\"5\":\"12202\",\"6\":\"2012\",\"7\":\"91\"},{\"1\":\"6.503381\",\"2\":\"-5.003381\",\"3\":\"The Trump Prophecy\",\"4\":\"1.5\",\"5\":\"2710\",\"6\":\"2018\",\"7\":\"120\"},{\"1\":\"7.598502\",\"2\":\"-4.998502\",\"3\":\"Buck Breaking\",\"4\":\"2.6\",\"5\":\"1036\",\"6\":\"2021\",\"7\":\"155\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThe presence of two Justin Bieber films near the top of the list jumps out at me, as do the titles \"The Trump Prophecy\" and \"Buck Breaking\". If I had to guess, we're seeing films that have attracted more (negative) attention due to their content than would be expected based purely on the variables available to our model. This highlights a crucial shortcoming of our model: other than the genre tags, it doesn't incorporate any information about what the films are actually _about_.\n\nSame thing, but now the highest residuals:\n\n\n::: {.cell tbl-cap='Predicting average ratings - Highest residuals'}\n\n```{.r .cell-code}\naugment(lm_rating_fit, rating_model_dat) %>% \n  slice_max(.resid, n=20) %>% \n  select(.pred, .resid, primaryTitle:runtimeMinutes)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".pred\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".resid\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"primaryTitle\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"averageRating\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"numVotes\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"startYear\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"runtimeMinutes\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"4.483153\",\"2\":\"4.416847\",\"3\":\"River Beauty\",\"4\":\"8.9\",\"5\":\"1036\",\"6\":\"2023\",\"7\":\"90\"},{\"1\":\"4.847855\",\"2\":\"4.252145\",\"3\":\"Akkada Varu Ikkada Unnaru\",\"4\":\"9.1\",\"5\":\"1030\",\"6\":\"2024\",\"7\":\"103\"},{\"1\":\"5.261594\",\"2\":\"3.838406\",\"3\":\"Kaveri\",\"4\":\"9.1\",\"5\":\"1463\",\"6\":\"2024\",\"7\":\"101\"},{\"1\":\"5.488597\",\"2\":\"3.711403\",\"3\":\"Ennu Swantham Punyalan\",\"4\":\"9.2\",\"5\":\"1354\",\"6\":\"2025\",\"7\":\"127\"},{\"1\":\"5.794335\",\"2\":\"3.705665\",\"3\":\"Jithender Reddy\",\"4\":\"9.5\",\"5\":\"2303\",\"6\":\"2024\",\"7\":\"136\"},{\"1\":\"5.714118\",\"2\":\"3.685882\",\"3\":\"Devaki Nandana Vasudeva\",\"4\":\"9.4\",\"5\":\"2527\",\"6\":\"2024\",\"7\":\"128\"},{\"1\":\"5.433433\",\"2\":\"3.666567\",\"3\":\"Antha Naal\",\"4\":\"9.1\",\"5\":\"1177\",\"6\":\"2024\",\"7\":\"98\"},{\"1\":\"5.387368\",\"2\":\"3.612632\",\"3\":\"Hide N Seek\",\"4\":\"9.0\",\"5\":\"2120\",\"6\":\"2024\",\"7\":\"134\"},{\"1\":\"5.290156\",\"2\":\"3.609844\",\"3\":\"Thursday\",\"4\":\"8.9\",\"5\":\"4813\",\"6\":\"2006\",\"7\":\"89\"},{\"1\":\"5.234139\",\"2\":\"3.565861\",\"3\":\"Darshini\",\"4\":\"8.8\",\"5\":\"2128\",\"6\":\"2024\",\"7\":\"120\"},{\"1\":\"6.320235\",\"2\":\"3.479765\",\"3\":\"Nimma Vasthugalige Neeve Javaabdaararu\",\"4\":\"9.8\",\"5\":\"2685\",\"6\":\"2025\",\"7\":\"132\"},{\"1\":\"6.154545\",\"2\":\"3.445455\",\"3\":\"Nesippaya\",\"4\":\"9.6\",\"5\":\"2057\",\"6\":\"2025\",\"7\":\"144\"},{\"1\":\"5.956542\",\"2\":\"3.443458\",\"3\":\"Va Varalam Va\",\"4\":\"9.4\",\"5\":\"1166\",\"6\":\"2023\",\"7\":\"139\"},{\"1\":\"5.370231\",\"2\":\"3.429769\",\"3\":\"Raktaksha\",\"4\":\"8.8\",\"5\":\"1349\",\"6\":\"2024\",\"7\":\"118\"},{\"1\":\"4.712875\",\"2\":\"3.387125\",\"3\":\"Bairan Palli\",\"4\":\"8.1\",\"5\":\"2240\",\"6\":\"2023\",\"7\":\"91\"},{\"1\":\"5.727435\",\"2\":\"3.372565\",\"3\":\"Paagal vs Kadhal\",\"4\":\"9.1\",\"5\":\"2049\",\"6\":\"2024\",\"7\":\"111\"},{\"1\":\"6.146140\",\"2\":\"3.353860\",\"3\":\"Strawberry Melancholy\",\"4\":\"9.5\",\"5\":\"4191\",\"6\":\"2007\",\"7\":\"112\"},{\"1\":\"5.247476\",\"2\":\"3.352524\",\"3\":\"Rhino King\",\"4\":\"8.6\",\"5\":\"1212\",\"6\":\"2025\",\"7\":\"90\"},{\"1\":\"5.850483\",\"2\":\"3.349517\",\"3\":\"Thiru.Manickam\",\"4\":\"9.2\",\"5\":\"2052\",\"6\":\"2024\",\"7\":\"122\"},{\"1\":\"5.757592\",\"2\":\"3.342408\",\"3\":\"Song Without Words\",\"4\":\"9.1\",\"5\":\"1112\",\"6\":\"2022\",\"7\":\"83\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nThese appear to be mainly non-English titles, released recently, with relatively few votes (recall that our threshold for inclusion in the data set was 1000 votes).\n\n\n### Random forest\n\nWith only a few extra lines of code, we can run the same analysis using a different model! Let's try a random forest model -- all we need to do is set up the engine we want to use (`ranger`), specifying the mode (`regression`, since our outcome is continuous), the number of trees (`trees`), and the method to be used to assess variable importance (`importance`)[^hyper].\n\n[^hyper]: Many models, including random forest and XGBoost, allow us to set _hyperparameters_ such as the number of trees or the number of predictors to sample at each split. For this post, I've manually set the number of trees but left all other hyperparameters at their default values. I'll cover methods for finding the optimal values for hyperparameters (knowing as _tuning_) in a future post; I'm skipping over it here because it can be both time- and processor-intensive!\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the engine\nrf_mod <- rand_forest(mode = \"regression\", trees = 1000) %>%\n  set_engine(\"ranger\", importance=\"impurity\") \n\n# Set workflow and fit model\nrf_rating_fit <- workflow() %>% \n  add_model(rf_mod) %>% \n  add_recipe(rating_rec) %>% # Same recipe as before! \n  fit(data = rating_data_train)\n\nrf_rating_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_log()\n• step_normalize()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1)) \n\nType:                             Regression \nNumber of trees:                  1000 \nSample size:                      33456 \nNumber of independent variables:  25 \nMtry:                             5 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       0.7761085 \nR squared (OOB):                  0.442483 \n```\n\n\n:::\n:::\n\n\n### XGBoost\n\nWe'll fit a third model using XGBoost:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the engine\nxgb_mod <- boost_tree(engine = \"xgboost\", mode = \"regression\", trees = 1000)\n\n# Set workflow and fit model\nxgb_rating_fit <- workflow() %>% \n  add_model(xgb_mod) %>% # Use XGBoost\n  add_recipe(rating_rec) %>%  # Same recipe as before!\n  fit(data = rating_data_train)\n\nxgb_rating_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n3 Recipe Steps\n\n• step_log()\n• step_normalize()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 3.7 Mb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1, \n    subsample = 1), data = x$data, nrounds = 1000, watchlist = x$watchlist, \n    verbose = 0, nthread = 1, objective = \"reg:squarederror\")\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", nthread = \"1\", objective = \"reg:squarederror\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 25 \nniter: 1000\nnfeatures : 25 \nevaluation_log:\n  iter training_rmse\n <num>         <num>\n     1     4.1600833\n     2     2.9903320\n   ---           ---\n   999     0.4058402\n  1000     0.4054915\n```\n\n\n:::\n:::\n\n\n### Compare\n\n#### Metrics\n\nTo compare our models, we first define a set of metrics:\n\n- Root mean square deviation (`rmse`): measures the deviation between observed and model-predicted values. Smaller values represent better fit; a value of 0 (impossible in practice) would represent perfect fit.\n- R-squared (`rsq`): proportion of variance in outcome variable predicted by the model. Ranges from 0.0 to 1.0; larger values represent better fit, with a value of 1.0 (impossible in practice) representing perfect fit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define metrics\nrating_metrics <- metric_set(rmse, rsq)\n```\n:::\n\n\nNext, we loop over a list of our models, using the `augment()` function to calculate these metrics for each model. First, let's see what happens if we calculate these metrics using the _training_ data:\n\n\n::: {.cell tbl-cap='Predicting average ratings - Model metrics (training data)'}\n\n```{.r .cell-code}\n# Make list of models\nrating_models <- list(\"Linear\"=lm_rating_fit,\n                      \"Random Forest\"=rf_rating_fit,\n                      \"XGBoost\" = xgb_rating_fit)\n\nrating_models %>% \n  map(\\(model) \n      augment(model, rating_data_train) %>% # Use training data\n        rating_metrics(averageRating, .pred)) %>% \n  list_rbind(names_to = \"Model\") %>% \n  select(-.estimator) %>% \n  pivot_wider(names_from = .metric, values_from = .estimate)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Model\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"rmse\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rsq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Linear\",\"2\":\"0.9321806\",\"3\":\"0.3757640\"},{\"1\":\"Random Forest\",\"2\":\"0.6902310\",\"3\":\"0.6885842\"},{\"1\":\"XGBoost\",\"2\":\"0.4054915\",\"3\":\"0.8919465\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nXGBoost appears superior by both metrics, but there's a big caveat -- models such as XGBoost (and random forests, to a lesser extent) are prone to _overfitting_, meaning that their predictions can be hyper-specialized for the data they were trained upon (e.g., `rating_data_train`) at the expense of their ability to generalize to novel data. To check, we'll calculate our metrics again, but this time we'll use our _test_ data (`rating_data_test`):\n\n\n\n::: {.cell tbl-cap='Predicting average ratings - Model metrics (test data)'}\n\n```{.r .cell-code}\nrating_models %>% \n  map(\\(model) \n      augment(model, rating_data_test) %>% # Use test data\n        rating_metrics(averageRating, .pred)) %>% \n  list_rbind(names_to = \"Model\") %>% \n  select(-.estimator) %>% \n  pivot_wider(names_from = .metric, values_from = .estimate)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Model\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"rmse\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"rsq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Linear\",\"2\":\"0.9240641\",\"3\":\"0.3819300\"},{\"1\":\"Random Forest\",\"2\":\"0.8699871\",\"3\":\"0.4543605\"},{\"1\":\"XGBoost\",\"2\":\"0.9394241\",\"3\":\"0.3844094\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nNote that our linear model performs roughly the same, but our random forest and XGBoost models show decreased performance. In particular, while XGBoost appeared to outperform the random forest model on the training data, it performs roughly equivalent to the linear model on the test data.\n\nThe takeaway here is that estimating our metrics based on the _training_ data inflated the performance of our random forest and (in particular) XGBoost models; using the _test_ data gives a much more accurate estimate of our metrics. \n\n#### Variable importance\n\nWe can use the `vip` package to get estimates of variable importance from each of our models, then plot them together:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrating_models %>% \n  map(\\(model) vip::vi(model,scale = T)) %>% # Scale makes estimates comparable\n  list_rbind(names_to = \"Model\") %>% \n  ggplot(aes(x=fct_reorder(Variable, Importance, mean), # Order by mean\n             y = Importance, \n             fill = Model, color = Model, shape = Model)) + \n  geom_point(alpha=0.8, size=3) +\n  coord_flip() + \n  labs(title = \"Predicting average rating - Variable importance\",\n       x = \"Variable\", y = \"Importance (scaled)\",\n       caption = \"Variables in descending order of mean importance\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-27-1.png){width=672}\n:::\n:::\n\n\nThere's some divergence between the three models, but overall, number of votes, run time, and release year seem to be the most important predictors across models.\n\n#### Predicted versus observed ratings\n\nLastly, let's compare the predicted versus observed ratings for each of our three models:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrating_models %>% \n  map(\\(model) augment(model, rating_data_test)) %>% \n  list_rbind(names_to=\"Model\") %>% \n  ggplot(aes(x=.pred,y=averageRating))+\n  geom_hex()+\n  geom_abline(slope = 1) + \n  coord_fixed() + \n  scale_fill_viridis_c()+\n  labs(x=\"Predicted average rating\",y=\"Average rating\", fill = \"Frequency\",\n       title = \"Predicting average rating - Predicted versus observed ratings\")+\n  facet_wrap(~Model,nrow = 2) + \n  theme(legend.position = \"inside\", legend.position.inside = c(.75,.25))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\nThe more closely the distribution follows the diagonal line, the more closely the predicted ratings match the observed ratings. Overall, the XGBoost model seems to have a slight advantage.\n\n## Predicting genre\n\nAll of our models thus far have examined continuous outcomes. Now, let's try some models with a categorical outcome. Specifically, let's see if we can predict whether or not a movie is classified as a drama based on the variables available to us! As with the previous example, we'll run three models and compare the results: binary logistic regression (GLM), random forest, and XGBoost.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define our data set\ndrama_model_dat <- rating_model_dat %>% \n  mutate(Drama = factor(Genre_Drama, labels = c(\"no\",\"yes\"))) %>% \n  select(-Genre_Drama)\n\n# Split data into training/testing sets\n# Setting `strata = Drama` ensures that proportion of positive cases\n# is roughly equal in training vs test set\nset.seed(1337)\ngenre_data_split <- initial_split(drama_model_dat, strata = Drama)\ngenre_data_train <- training(genre_data_split)\ngenre_data_test <- testing(genre_data_split)\n\n# Set the recipe\ngenre_rec <- recipe(Drama ~ ., genre_data_train) %>% \n  step_log(numVotes) %>% \n  step_normalize(averageRating,startYear,runtimeMinutes,numVotes) %>% \n  update_role(tconst,primaryTitle,new_role = \"ID\") # Treat as identifiers\n```\n:::\n\n\n\n\n### GLM\n\nSetting up the engine for GLM is straightforward; we technically don't need to specify `mode` or `engine`, since `logistic_reg()` defaults to `mode = \"classification\"` and `engine = \"glm\"`, but I've included them here for completeness.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the engine\ngenre_mod <- logistic_reg(mode = \"classification\",\n                          engine = \"glm\")\n\n# Set the workflow\ngenre_workflow <- workflow() %>% \n  add_model(genre_mod) %>% \n  add_recipe(genre_rec)\n\n# Fit model\ngenre_fit <- genre_workflow %>% \n  fit(data = genre_data_train)\n\n# Check results\ngenre_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_log()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n      (Intercept)      averageRating           numVotes          startYear  \n          3.75923            0.45874            0.09723            0.10283  \n   runtimeMinutes      Genre_Romance  Genre_Documentary        Genre_Sport  \n          0.20793           -0.54392           -6.32332           -0.89793  \n     Genre_Action    Genre_Adventure    Genre_Biography      Genre_Fantasy  \n         -1.91524           -1.75050           -0.18449           -1.18757  \n     Genre_Comedy          Genre_War        Genre_Crime       Genre_Family  \n         -3.16581           -0.39853           -0.71781           -1.32834  \n    Genre_History     `Genre_Sci-Fi`     Genre_Thriller      Genre_Western  \n         -0.37178           -2.00270           -2.29839           -2.35082  \n    Genre_Mystery       Genre_Horror        Genre_Music    Genre_Animation  \n         -0.94367           -2.74321           -0.47075           -2.35175  \n    Genre_Musical  `Genre_Film-Noir`        Genre_Adult  \n         -1.57199           -0.31297                 NA  \n\nDegrees of Freedom: 33454 Total (i.e. Null);  33429 Residual\nNull Deviance:\t    46010 \nResidual Deviance: 28000 \tAIC: 28050\n```\n\n\n:::\n:::\n\n\n### Random forest\n\nFor a random forest model, we'll pass a few more arguments to set up the engine.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the engine\ngenre_rf <- rand_forest(trees = 1000) %>%\n  set_engine(\"ranger\", importance=\"impurity\") %>%\n  set_mode(\"classification\")\n\n\n# Set the workflow\ngenre_workflow_rf <- workflow() %>% \n  add_model(genre_rf) %>% \n  add_recipe(genre_rec)\n\n# # Finalize model and fit\ngenre_fit_rf <- genre_workflow_rf %>%\n  fit(data = genre_data_train)\n\n# Check results\ngenre_fit_rf\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_log()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, num.trees = ~1000,      importance = ~\"impurity\", num.threads = 1, verbose = FALSE,      seed = sample.int(10^5, 1), probability = TRUE) \n\nType:                             Probability estimation \nNumber of trees:                  1000 \nSample size:                      33455 \nNumber of independent variables:  26 \nMtry:                             5 \nTarget node size:                 10 \nVariable importance mode:         impurity \nSplitrule:                        gini \nOOB prediction error (Brier s.):  0.1170917 \n```\n\n\n:::\n:::\n\n\n\n### XGBoost\n\nLastly, let's run an XGBoost model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenre_xgb <- boost_tree() %>%\n  set_engine(\"xgboost\") %>% \n  set_mode(\"classification\")\n\n# Set the workflow\ngenre_workflow_xgb <- workflow() %>% \n  add_model(genre_xgb) %>% \n  add_recipe(genre_rec)\n\n# Finalize model and fit\ngenre_fit_xgb <- genre_workflow_xgb %>% \n  fit(data = genre_data_train)\n\ngenre_fit_xgb\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: boost_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n2 Recipe Steps\n\n• step_log()\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n##### xgb.Booster\nraw: 61.5 Kb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1, \n    subsample = 1), data = x$data, nrounds = 15, watchlist = x$watchlist, \n    verbose = 0, nthread = 1, objective = \"binary:logistic\")\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", nthread = \"1\", objective = \"binary:logistic\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  niter\ncallbacks:\n  cb.evaluation.log()\n# of features: 26 \nniter: 15\nnfeatures : 26 \nevaluation_log:\n  iter training_logloss\n <num>            <num>\n     1        0.5921049\n     2        0.5357200\n   ---              ---\n    14        0.3776050\n    15        0.3730612\n```\n\n\n:::\n:::\n\n\n### Compare\n\n#### Metrics\n\nAs previously, we'll define a set of metrics to compare our model:\n\n- Accuracy (`accuracy`): measures the proportion of cases that are predicted correctly. Values closer to 1.00 indicate greater accuracy.\n- Kappa (`kap`): like accuracy, but adjusted based on the proportion of correct predictions that would be expected due to chance alone.\n- Sensitivity (`sensitivity`): the number of _predicted positives_ divided by the number of _actual positives_. In our case, what proportion of films with the \"drama\" tag did our models correctly predict as dramas?\n- Specificity (`specificity`): the number of _predicted negatives_ divided by the number of _actual negatives_. In our case, what proportion of non-drama films did our models correctly predict as non-dramas?\n\n\n::: {.cell tbl-cap='Predicting drama - Model metrics'}\n\n```{.r .cell-code}\n# Define metrics\ngenre_metrics <- metric_set(\n  yardstick::accuracy,\n  kap, \n  sensitivity,\n  specificity\n)\n\n# Make list of models, augment with predictions\ngenre_models_augmented <- list(\"GLM\"=genre_fit,\n                               \"Random Forest\"=genre_fit_rf,\n                               \"XGBoost\"=genre_fit_xgb) %>% \n  map(\\(model) augment(model, genre_data_test)) # Get predictions from test dat\n  \n# Get metrics\ngenre_models_augmented %>% \n  map(\\(model) genre_metrics(model, truth = Drama, estimate =.pred_class)) %>% \n  list_rbind(names_to = \"Model\") %>% \n  select(-.estimator) %>% \n  pivot_wider(names_from = .metric, values_from = .estimate)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Model\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"accuracy\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"kap\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sensitivity\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"specificity\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"GLM\",\"2\":\"0.7831077\",\"3\":\"0.5589493\",\"4\":\"0.7280737\",\"5\":\"0.8277318\"},{\"1\":\"Random Forest\",\"2\":\"0.8356496\",\"3\":\"0.6671247\",\"4\":\"0.8077693\",\"5\":\"0.8582562\"},{\"1\":\"XGBoost\",\"2\":\"0.8259661\",\"3\":\"0.6474449\",\"4\":\"0.7959551\",\"5\":\"0.8503004\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nOur random forest and XGBoost models appear to perform better than our GLM, but don't differ substantially from each other.\n\nWe can also assess our models in terms of their receiver operating characteristic (ROC) curves. We'll run `roc_curve()` on each of our models, then bind the data together and plot with `ggplot()`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngenre_models_augmented %>% \n  map(~roc_curve(.x, truth = Drama, .pred_no)) %>% # Calculate ROC curves\n  list_rbind(names_to = \"Model\") %>% # Bind into single data frame\n  ggplot(aes(x = 1-specificity,y=sensitivity,color=Model)) + \n  geom_line() + # Plot the curves\n  geom_abline(linetype=3) + # Add diagonal line for reference\n  coord_fixed() + # Make plot square\n  labs(title=\"Predicting drama - ROC curves by model\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\nThese curves describe the relationship between a model's true positive rate (sensitivity) and its false positive rate (1-specificity). If a model predicted a binary outcome purely at random, its true positive rate would always be equal to its false positive rate, and its \"curve\" would fall on the dotted diagonal line; the better a model predicts the outcome, the farther the curve curves away from the diagonal. Out of our three models, the random forest appears to slightly outperform the XGBoost, and both outperform the GLM, as seen from the fact that their curves bend farther from the diagonal (put another way, for any level of specificity, these models have equal or greater sensitivity than the GLM).\n\nWe can quantify the difference between the models' ROC curves by calculating the area under the curve (AOC) for each model. Values closer to 1.00 indicate greater performance.\n\n\n::: {.cell tbl-cap='Predicting drama - ROC AUC'}\n\n```{.r .cell-code}\ngenre_models_augmented %>% \n  map(\\(model) roc_auc(model, \n                       truth = Drama, \n                       .pred_yes, event_level=\"second\")) %>% \n  list_rbind(names_to = \"Model\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Model\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".metric\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"GLM\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.8821782\"},{\"1\":\"Random Forest\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.9178467\"},{\"1\":\"XGBoost\",\"2\":\"roc_auc\",\"3\":\"binary\",\"4\":\"0.9090270\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nHere again, the random forest model slightly outperforms the XGBoost model, and both outperform the GLM.\n\n#### Variable importance\n\nFinally, let's plot estimates of variable importance for each model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\"GLM\"=genre_fit,\n     \"Random Forest\"=genre_fit_rf,\n     \"XGBoost\"=genre_fit_xgb) %>% \n  map(\\(model) vip::vi(model,scale = T)) %>% \n  list_rbind(names_to = \"Model\") %>% \n  ggplot(aes(x=fct_reorder(Variable, Importance, mean), y = Importance, \n             fill = Model, color = Model, shape = Model)) + \n  geom_point(size=3) +\n  coord_flip() +\n  labs(x=\"Variable\",\n       y=\"Importance (scaled)\",\n       title = \"Predicting drama - Variable importance\",\n       caption = \"Variables in descending order of mean importance\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n:::\n\n\nThe genre tags for comedy and drama appear to be most important regardless of model; however, estimates of importance for variables like average rating, number of votes, and release year differ substantially by model (higher for random forest and XGBoost, lower for GLM). In a real-world scenario, we'd want to dig deeper, potentially using a permutation-based method to assess the variability of these estimates.\n\n\n# Wrapping up\n\nPhew -- that was a lot! We began by reading in multiple data sets from IMBD, webscraping lifetime gross data from Box Office Mojo, then joining these to produce a data set of movies that included ratings, director names, and lifetime domestic gross (where available). We then used `tidymodels` package to set up modelling workflows to predict lifetime gross, average rating, and genre based on all variables available to us. For the latter two, we ran multiple models, then compared performance and estimates of variable importance.\n\nI'm really enjoying what I've seen of `tidymodels` thus far -- I find myself spending more time thinking about the model itself, and less time wrestling with the implementation. The ability to quickly switch engines (e.g., from linear regression to random forest to XGBoost) and easily compare results is another huge plus, since it makes it much easier to answer the type of \"Hmmm, what if we tried...\" questions that arise so often in modelling. I hope to do a deeper dive into `tidymodels` and its capabilities in a future post!\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}